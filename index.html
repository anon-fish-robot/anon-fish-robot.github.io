<!DOCTYPE html>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-chtml.js">
</script>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta property="og:title" content="Watch and Match: Supercharging Imitation with Regularized Optimal Transport">
  <meta property="og:description" content="Watch and Match: Supercharging Imitation with Regularized Optimal Transport">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Watch and Match: Supercharging Imitation with Regularized Optimal Transport">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Watch and Match: Supercharging Imitation with Regularized Optimal Transport">
  <meta name="twitter:description"
    content="We propose a new imitation learning algorithm that substantially improves sample efficiency for continuous control problems in simulation and on real-world robotic manipulation tasks.">
  <meta name="twitter:image" content="./mfiles/arch bet.001.png" />
  <link rel="shortcut icon" href="img/favicon.png">
  <link rel="stylesheet" href="css/simple-grid.css">
  <title>Teach a Robot to FISH: Versatile Imitation from
One Minute of Demonstrations</title>
</head>

<body>
  <div class="jumbotron">
    <div class="container">
      <div class="row">
        <div class="col-13 center">
          <h1>Hello</h1>
        </div>
        <div class="col-3 hidden-sm"></div>
        <div class="col-2 center">
          <!--<a style="text-decoration: none" href="https://openreview.net/pdf?id=ZUtgUA0Fuwd" download>
            <h3 style="color: #F5A803">Paper</h3>
          </a> -->
        </div>
        <div class="col-2 center">
          <a style="text-decoration: none" href="Hello" download>
            <h3 style="color: #F5A803">Data</h3>
          </a>
        </div>
        <div class="col-2 center">
          <a style="text-decoration: none" href="https://osf.io/vyu7q/?view_only=040ed766b96847b4aadaba8acd6ab3dd" download>
            <h3 style="color: #F5A803">Code</h3>
          </a>
        </div>
      </div>

      <!--Intro video-->
      <div class="intro-vid">
        <div class="container">
          <div class="col-12">
            <!-- <video class="img" style="height: 600" controls loop>
              <source src="./mfiles/videos/ROT_full.mp4" type="video/mp4">
            </video> -->
            <body>
              <iframe width="711" height="400" src="" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </body>
          </div>
        </div>
      </div>

      <!--Abstract-->
      <div class="row">
        <div class="col-12">
          <h2 class="center m-bottom">Abstract</h2>
          <p>
            While imitation learning provides us with an effi-
cient toolkit to train robots, learning skills that are robust to
environment variations remains a significant challenge. Current
approaches address this challenge by relying either on large
amounts of demonstrations that span environment variations or
on handcrafted reward functions that require state estimates.
Both directions are not scalable to fast imitation. In this work,
we present Fast Imitation of Skills from Humans (FISH), a
new imitation learning approach that can learn robust visual
skills with less than a minute of human demonstrations. Given a
weak base-policy trained by offline imitation of demonstrations,
FISH computes rewards that correspond to the “match” between
the robot’s behavior and the demonstrations. These rewards
are then used to adaptively update a residual policy that adds
on to the base-policy. Across all tasks, FISH requires at most
twenty minutes of interactive learning to imitate demonstrations
on object configurations that were not seen in the demonstrations.
Importantly, FISH is constructed to be versatile, which allows it
to be used across robot morphologies (e.g. xArm, Allegro, Stretch)
and camera configurations (e.g. third-person, eye-in-hand). Our
experimental evaluations on 9 different tasks show that FISH
achieves an average success rate of 93%, which is around 3.8×
higher than prior state-of-the-art methods.
          </p>
        </div>
      </div>
    </div>
    <!--Videos-->
    <!-- <div class="intro-vid">
      <div class="container">
        <div class="col-12">
          <video class="img" style="height: 600" controls loop>
            <source src="./mfiles/videos/ROT_full.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div> -->
    <!-- <div class="container">
      <div class="row">
        <div class="col-12">
          <h2 class="center m-bottom">Real-World Results</h2>
          <p>We provide evaluation rollouts of ROT on a set of 14 real-world manipulation tasks. With just one demonstration and one hour of
             online training, ROT achieved an average sucess rate of 90.1% across 14 tasks. This is significantly higher than behavior 
             cloning (36.1%) and adversarial IRL (14.6%) based approaches.
          </p>
        </div>
      </div>
    </div>
    <br><br> -->
    <!-- <div class="body-content">
      <div class="container">
        <div class="grid-display">
          <div class="row">
            <div class="col-6">
              <img class="img" style="height: 600" src="./mfiles/gifs/closedoor.gif">
            </div>
            <div class="col-6">
              <img class="img" style="height: 600" src="./mfiles/gifs/hanghanger.gif">
            </div>
          </div>
          <div class="row">
            <div class="col-6">
              <img class="img" style="height: 600" src="./mfiles/gifs/eraseboard.gif">
            </div>
            <div class="col-6 center">
             <img class="img" style="height: 600" src="./mfiles/gifs/reach.gif">
            </div>
          </div>
          <div class="row">
            <div class="col-6">
              <img class="img" style="height: 600" src="./mfiles/gifs/hangcup.gif">
            </div>
            <div class="col-6">
              <img class="img" style="height: 600" src="./mfiles/gifs/hangbag.gif">
            </div>
          </div>
          <div class="row">
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/turnknob.gif">
            </div>
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/stackcups.gif">
            </div>
          </div>
          <div class="row">
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/pressbutton.gif">
            </div>
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/insertpegeasy.gif">
            </div>
          </div>
          <div class="row">
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/insertpegmed.gif">
            </div>
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/insertpeghard.gif">
            </div>
          </div>
          <div class="row">
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/openbox.gif">
            </div>
            <div class="col-6 left">
              <img class="img" style="height: 600" src="./mfiles/gifs/pour.gif">
            </div>
          </div>
        </div>
      </div>
    </div> -->

    <!-- <div class="column center"> 
      <div class="row">
      <img src="./mfiles/gifs/closedoor.gif" style="max-width:200px">
      <img src="./mfiles/gifs/hanghanger.gif" style="max-width:200px">
      <img src="./mfiles/gifs/eraseboard.gif" style="max-width:200px">
      <img src="./mfiles/gifs/reach.gif" style="max-width:200px">
      <img src="./mfiles/gifs/hangcup.gif" style="max-width:200px">
      <img src="./mfiles/gifs/hangbag.gif" style="max-width:200px">
      <img src="./mfiles/gifs/turnknob.gif" style="max-width:200px">
      </div>
      <div class="row">
        <img src="./mfiles/gifs/stackcups.gif" style="max-width:200px">
        <img src="./mfiles/gifs/pressbutton.gif" style="max-width:200px">
        <img src="./mfiles/gifs/insertpegeasy.gif" style="max-width:200px">
        <img src="./mfiles/gifs/insertpegmed.gif" style="max-width:200px">
        <img src="./mfiles/gifs/insertpeghard.gif" style="max-width:200px">
        <img src="./mfiles/gifs/openbox.gif" style="max-width:200px">
        <img src="./mfiles/gifs/pour.gif" style="max-width:200px">
      </div>
    </div> -->
    <!-- <div class="column center"> 
      <div class="row">
      <img src="./mfiles/gifs/combined_gif_cropped.gif" style="width: 50%;">
      </div>
    </div> -->

    <!--Image-->
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2 class="center m-bottom">Method</h2>
          <p><a style="color: #00A2FF; font-weight: bold;">Hello
        </div>
      </div>
    </div>
    <div class="row">
      <div class="center img">
        <img src="./mfiles/hello1.png" style="max-width:1500px;width:50%" frameborder="0"
          allowfullscreen></img>
      </div>
    </div>

    <!--Method-->
    <div class="container">
      <div class="row">
        <div class="col-12">
          <p>Given a few demonstrations for complex, contact-rich ma-
            nipulation that covers a small subset of possible object con-
            figurations, we seek to learn a robot policy that can gener-
            alize to a larger set of configurations not seen during the
            demonstrations. To enable this, we propose Fast Imitation of
            Skills from Humans (FISH). FISH operates in two phases.
            In the first phase, a weak base policy is trained on the few
            demonstrations using supervised learning. This weak policy,
            while being poor in generalization, serves as a useful prior for
            subsequent adaptation. In the second phase, a residual policy is
            trained to adapt the base policy to new object configurations.
            This is done by RL on the robot with these configurations
            using visual trajectory matching scores as the reward signal.
          <ul style="font-size: 1.125rem;font-weight: 200;line-height: 1.8">
            <li>Hello</li>
          </ul>
          </p>
        </div>
      </div>
    </div>

    <!--Experiments-->
    <div class="container">
      <div class="row">
        <div class="col-12">
          <!-- <h2 class="center m-bottom">Experiments</h2>
          <p>To demonstrate the effectiveness of ROT, we run extensive experiments on 20 simulated tasks across
            DM Control, OpenAI Robotics, and Meta-world, and 14 robotic manipulation tasks on an xArm. For DM Control, we 
            measure the average episode reward. For OpenAI Robotics, Meta-world and the real-world xArm tasks, we measure the number
            of successful trajectories. Evaluations are over 10 trajectories for the simulated tasks and 20 trajectories for the 
            real-world tasks. To reach 90% of expert performance, ROT is on average
          </p> -->
          <!-- <h2 class="center m-bottom">Simulation Results</h2>
          <p>Hello
          </p>
          <ul style="font-size: 1.125rem;font-weight: 200;line-height: 1.8">
            <li> Hello</li>
            <img class="center" src="./mfiles/appendix_pixel_results_dmc.png" style="width:100%"></img>
            <li>Hello</li>
            <img class="center" src="./mfiles/appendix_pixel_results_fetch.png" style="width:100%"></img>
            <li>Hello</li>
            <img class="center" src="./mfiles/appendix_pixel_results_metaworld.png" style="width:100%"></img>
          </ul>
          </p> -->
          <h2 class="center m-bottom">Robot Results</h2>
          <p>Hello
          </p>
          <img src="./mfiles/gifs/combined_gif_cropped.gif" style="width: 100%;">
          <img class="center" src="./mfiles/robot_exp_combined_cropped.png" style="width:100%"></img>
          <!-- <img class="center" src="./mfiles/robot_exp_combined.png" style="width:100%"></img> -->
          <br><br>
          <!-- <img class="center" src="./mfiles/robot_results.png" style="width:100%"></img> -->
        </div>
      </div>
    </div>

    <!--Future Work-->
    <div class="container" style="padding-bottom: 150px; padding-top: 20px">
      <div class="row">
        <div class="col-12">
          <h2 class="center m-bottom">Limitations and Future Work</h2>
          <p>we recognize a few
            limitations in this work: (a) Since the OT-based rewards
            used to train the residual policy aligns the agent with the demonstrations, it relies on the demonstrator being an ‘expert’.
            (b) We restrict ourselves to the visual domain which makes
            it difficult to perform precise tasks where the visual signals
            are not very prominent. For example, it is difficult to infer a
            key hole spanning a miniscule portion of an image. A potential
            improvement along this line might result from embracing other
            modalities such as tactile sensing. (c) Our residual policy is
            randomly initialized. Pretraining the residual policy might help
            scale to more difficult tasks requiring more precise control.
            
          </p>
        </div>
      </div>
    </div>

  </div>
  <footer>
  </footer>
</body>

</html>
